{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A computer is a device that processes dataaccording to a set of instructions knownas a program\n",
      "['A', 'computer', 'is', 'a', 'device', 'that', 'processes', 'dataaccording', 'to', 'a', 'set', 'of', 'instructions', 'knownas', 'a', 'program']\n"
     ]
    }
   ],
   "source": [
    "trial_sample= \"A computer is a device that processes dataaccording to a set of instructions knownas a program\"\n",
    "trial_sample1=trial_sample.replace(\",\",\"\")\n",
    "trial_sample2=trial_sample1.replace(\".\",\"\")\n",
    "last_clean=trial_sample2.split()\n",
    "print(trial_sample2)\n",
    "print(last_clean)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "comput\n",
      "is\n",
      "a\n",
      "devic\n",
      "that\n",
      "process\n",
      "dataaccord\n",
      "to\n",
      "a\n",
      "set\n",
      "of\n",
      "instruct\n",
      "knowna\n",
      "a\n",
      "program\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "for i in last_clean:\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    print(stemmer.stem(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computer UsersINTRODUCTIONA computer is a device that processes dataaccording to a set of instructions knownas a program\n"
     ]
    }
   ],
   "source": [
    "file=open(\"Computer Reading.txt\",\"r+\",encoding=\"utf-8\")\n",
    "    \n",
    "icerik = file.read()\n",
    "\n",
    "icerik_birlestir= icerik.replace(\"\\n\",\"\")\n",
    "cumle_ayir=icerik_birlestir.split(\".\")\n",
    "print(cumle_ayir[0])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Computer Reading.txt\",\"r+\",encoding=\"utf-8\") as file:\n",
    "    liste= file.readlines()\n",
    "    liste2=[]\n",
    "    liste3= liste[2].split()\n",
    "    \n",
    "    for i in liste:\n",
    "        if(i.isupper()==True or (i.istitle()==True)):\n",
    "            liste2.append(\"\\n\")\n",
    "        else:\n",
    "            liste2.append(i)\n",
    "with open(\"Computer Reading Son.txt\",\"a\",encoding=\"utf-8\") as file1:\n",
    "    for i in liste2:\n",
    "        file1.write(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#String punctaution metodu kullanılabilir. \n",
    "with open(\"Computer Reading Son.txt\",\"r\",encoding=\"utf-8\") as file:   \n",
    "    icerik= file.read()\n",
    "    bosluk_sil= icerik.replace(\"\\n\",\" \")\n",
    "    nokta_sil=bosluk_sil.replace(\".\",\" \")\n",
    "    sagparantez_sil=nokta_sil.replace(\")\",\" \")\n",
    "    solparantez_sil=sagparantez_sil.replace(\"(\",\" \")\n",
    "    virgul_sil=solparantez_sil.replace(\",\",\" \")\n",
    "    noktalivirgul_sil=virgul_sil.replace(\";\",\" \")\n",
    "    unlem_sil=noktalivirgul_sil.replace(\"!\",\" \")\n",
    "    cızgı_sil=unlem_sil.replace(\"|\",\" \")\n",
    "    suslupsa_sil=cızgı_sil.replace(\"{\",\" \")\n",
    "    suslupso_sil=suslupsa_sil.replace(\"}\",\" \")\n",
    "    bosluk_sil=suslupso_sil.replace(\"       \",\" \")\n",
    "    strip_sil=bosluk_sil.strip()\n",
    "    son_hal=strip_sil.split()\n",
    "    x= set(son_hal)\n",
    "    son_list=list(x)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "\n",
    "with open(\"Computer Reading Son.txt\",\"r\",encoding=\"utf-8\") as file: \n",
    "    icerik=file.read()\n",
    "    yeni_string=\"\"\n",
    "    for i in icerik:\n",
    "        if i not in string.punctuation:\n",
    "            yeni_string += i \n",
    "    satir_sil= yeni_string.replace(\"\\n\",\" \")\n",
    "    bosluk_sil=satir_sil.replace(\"  \",\" \")\n",
    "    kelime_ayir=bosluk_sil.split()\n",
    "    kume_yap= set(kelime_ayir)\n",
    "    list_cevir= list(kume_yap)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stem_list=[]\n",
    "for i in list_cevir:\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    stem_list.append(stemmer.stem(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw</th>\n",
       "      <th>Root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>used</td>\n",
       "      <td>use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>incorporated</td>\n",
       "      <td>incorpor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>set</td>\n",
       "      <td>set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>keyboard</td>\n",
       "      <td>keyboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>server</td>\n",
       "      <td>server</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>wordprocessors</td>\n",
       "      <td>wordprocessor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>IRC</td>\n",
       "      <td>irc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>types</td>\n",
       "      <td>type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>disks</td>\n",
       "      <td>disk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>spreadsheets</td>\n",
       "      <td>spreadsheet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>434 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Raw           Root\n",
       "0              used            use\n",
       "1      incorporated       incorpor\n",
       "2               set            set\n",
       "3          keyboard       keyboard\n",
       "4            server         server\n",
       "..              ...            ...\n",
       "429  wordprocessors  wordprocessor\n",
       "430             IRC            irc\n",
       "431           types           type\n",
       "432           disks           disk\n",
       "433    spreadsheets    spreadsheet\n",
       "\n",
       "[434 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dict = {\"Raw\":list_cevir,\"Root\":stem_list}\n",
    "df= pd.DataFrame(dict)\n",
    "df.to_csv(\"Computer Reading Processing.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyDictionary import PyDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Noun': ['an educational institution', 'a building where young people receive education', 'the process of being formally educated at a school', 'a body of creative artists or writers or thinkers linked by a similar style or by similar teachers', 'the period of instruction in a school; the time period when school is in session', \"an educational institution's faculty and students\", 'a large group of fish'], 'Verb': ['educate in or as if in a school', 'teach or refine to be discriminative in taste or judgment', 'swim in or form a large group of fish']}\n"
     ]
    }
   ],
   "source": [
    "dict=PyDictionary()\n",
    "meaning = dict.meaning(\"School\")\n",
    "print(meaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['used', 'incorporated', 'set', 'keyboard', 'server', 'monitor', 'Medical', '‘Splat', 'sorted', 'aluminium', 'reproduce', 'plugging', 'logged', 'required', 'greetings', 'Dogpile', 'magnetic', 'fixed', 'email', 'household', 'store', 'combination', 'clicking', 'documents', 'website', 'operating', 'standards', 'storage', 'Common', 'receiving', '‘Pets', 'including', 'audio', 'multipurpose', 'Transfer', 'applications', 'do', 'etc', 'detect', 'see', 'for', 'simple', 'selling', 'example', 'share', 'Advanced', 'compatible', 'note', 'between', 'browser', 'writing', 'common', 'electronic', 'Chat', 'circuit', 'at', 'tools', 'larger', 'package', 'they', 'select', 'items', 'special', 'well', 'search', 'able', 'normally', 'interface', 'W', 'that', 'form', 'lists', 'style', 'enable', 'as', 'remove', 'systems', 'Word', 'music', 'their', 'hardware', 'while', 'inserted', 'find', 'features', 'user’s', 'chip’', 'home', 'cameras', 'one', 'graphics', 'using', 'Networks', 'variety', 'not', 'illness', 'Microsoft', 'with', 'coated', 'equipment', 'browsing', 'slots', 'becoming', 'ina', 'designed', 'stored', 'plugged', 'light', 'button', 'Various', 'interlinked', 'build', 'include', 'any', 'desk', 'menus', 'pressing', 'a', 'compact', 'user', 'uploading', 'integrated', 'graphic', 'influenced', 'eg', 'found', 'vast', 'known', 'access', 'entertainment', 'different', 'together', 'contains', 'carried', 'available', 'the', 'Worid', 'delay', 'connection', 'free', 'purpose', 'ie', 'handheld', 'mentioned', 'so', 'classrooms', 'Antivirus', 'chat', 'sockets', 'these', 'distance', 'same', 'also', 'single', 'PC', 'FTP', 'Internet', 'themselves', 'world', 'laser', 'disk', 'personal', 'video', 'parts', 'bank', 'software', 'images', 'interfaces', 'washing', 'treatment', 'services', 'referred', 'CDs', 'engines', 'and', 'done', 'processed', 'animation', 'File', 'popular', 'databases', 'Connecting', 'commonly', 'only', 'each', 'input', 'AskJeeves', 'most', 'help', 'resources', 'working', 'called', 'decide', 'desktop', 'phones', 'choices', 'Note', 'allow', 'communication', 'forms', 'laid', 'best', 'term', 'camera', 'Wide', 'files', 'clipart', 'cars', 'time', 'fridges', 'program', 'situations', 'packaged', 'or', 'WWW', 'PCs', 'stay', 'boardrooms', 'computer', 'an', 'often', 'There', 'applied', 'It', 'texts', 'being', 'processes', 'future', 'searched', 'They', 'creating', 'computers', 'main', 'downloading', 'programs', 'touch', 'painting', 'in', '‘think’', 'moving', 'learning', 'company', 'by', 'peripherals', 'device', 'Computer', 'on', 'start', 'provide', 'photographs', 'system', 'telecommute', 'very', 'attach', 'person', 'can', 'from', 'possible', 'editing', 'actually', 'uses', 'small', 'down', 'chip', 'microchip', 'displayed', 'An', 'signals', 'allows', 'Electronics', 'part', 'newest', 'Devices', 'attached', 'networks', 'wide', 'account', 'cannot', 'experts', 'multimedia', 'output', 'enclosed', 'text', 'pictures', 'paper', 'The', 'is', 'fo', 'graphical', 'way', 'printing', 'which', 'other', 'added', 'more', 'producing', 'balances', 'videoconferencing', 'mathematical', 'expansion', 'smart', 'are', 'mouse', 'One', 'Services', 'television', 'attachments', 'be', 'harmful', 'purposes', 'related', 'looks', 'Web', 'powerful', 'Cat’', 'Net', 'although', 'relevant', 'communicating', 'such', 'reading', 'hear', 'Websites', 'out', 'case', 'provides', 'to', 'machines', 'internet', 'Not', 'threedimensional', 'How', 'hard', 'simply', 'without', '‘computer', 'data', 'boards', 'information', 'CDROMs', 'connected', 'plastic', 'built', 'readydrawn', 'unit', 'This', 'sending', 'calculating', 'messages', 'users', 'password', 'people', '‘connectivity’', 'come', 'service', 'interactive', 'viruses', 'screen', 'Protocol', 'wordprocessing', 'have', 'transferring', 'communicate', 'health', 'over', 'scanning', 'edutainment', 'instructions', 'taking', '3’', 'Those', 'A', 'Some', 'Relay', 'webpage', 'storing', 'vacuumsealed', 'use', 'enables', 'what', 'formulae', 'gradually', 'capital', 'diagnose', 'digital', 'licences', 'typewriter', 'expert', 'client', 'copying', 'office', 'sound', 'realtime', 'printer', 'mail', 'records', 'give', 'security', 'As', 'this', 'memory', 'range', 'inputting', 'of', 'Unlike', 'drivers’', 'cards', 'developed', 'sometimes', 'doctors', 'like', 'IBM', 'name', 'process', 'superhighway', 'network', 'throughout', 'webpages', 'sizes', 'according', 'education', 'into', 'usually', 'around', 'read', 'material', 'devices', 'all', 'externally', 'wordprocessors', 'IRC', 'types', 'disks', 'spreadsheets']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "with open(\"Computer Reading Son.txt\",\"r\",encoding=\"utf-8\") as file: \n",
    "    icerik=file.read()\n",
    "    yeni_string=\"\"\n",
    "    for i in icerik:\n",
    "        if i not in string.punctuation:\n",
    "            yeni_string += i \n",
    "    satir_sil= yeni_string.replace(\"\\n\",\" \")\n",
    "    bosluk_sil=satir_sil.replace(\"  \",\" \")\n",
    "    kelime_ayir=bosluk_sil.split()\n",
    "    kume_yap= set(kelime_ayir)\n",
    "    list_cevir= list(kume_yap)\n",
    "    yeni_string\n",
    "    for i in list_cevir:\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e9707c37b537b8f1292233dc6feb5c509e35d3b05cc9ac3d024c9f2e2c6a9134"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
