{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bea5276a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import string \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from googletrans import Translator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81af9510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def File_Content(file_name):\n",
    "    file_str = ''\n",
    "\n",
    "    if file_name.endswith('.pdf'):\n",
    "        pdf_file = convert_from_path(file_name)\n",
    "\n",
    "        for i in range(len(pdf_file)):\n",
    "            pdf_file[i].save(f'page{str(i + 1)}.jpg', 'JPEG')   # Saves pages as images in the pdf\n",
    "            file = f'page{str(i + 1)}.jpg'\n",
    "            file_str += pytesseract.image_to_string(file)\n",
    "            # os.remove(file)   # Deletes saved image files\n",
    "    elif file_name.endswith(('.jpg', '.png')):\n",
    "        file_str = pytesseract.image_to_string(file_name)\n",
    "        \n",
    "    return file_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b90ec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_cont= File_Content('Computer Reading.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a50414e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"Deneme.txt\",\"a\",encoding=\"utf-8\") as file:\n",
    "    file.write(file_cont)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa863202",
   "metadata": {},
   "outputs": [],
   "source": [
    "    with open(\"Deneme.txt\",\"r+\",encoding=\"utf-8\") as file:\n",
    "        content= file.readlines()\n",
    "        parag=  file.read()\n",
    "    \n",
    "\n",
    "        untitled=\"\"\n",
    "        for i in content:\n",
    "            if(i.isupper()==True or (i.istitle()==True)):\n",
    "                untitled += \" \"\n",
    "            else:\n",
    "                untitled += i + \" \"\n",
    "    with open(\"Computer Reading Son.txt\",\"a\",encoding=\"utf-8\") as file1:\n",
    "        for i in untitled:\n",
    "            file1.write(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7be3c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "from nltk.tokenize import sent_tokenize\n",
    "with open(\"Computer Reading Son.txt\",\"r\",encoding=\"utf-8\") as file: \n",
    "    contents=file.read()\n",
    "    content_clear =contents.replace(\"\\n\",\"\")\n",
    "    content_clear = content_clear.replace(\"/n\",\"\")\n",
    "    \n",
    "    def punctuation_clear(text):\n",
    "        result = \"\"\n",
    "        for i in text:\n",
    "            if( i not in string.punctuation or i == \" \" ):\n",
    "                result+= i \n",
    "            else:\n",
    "                result+= \"\"\n",
    "        return result\n",
    "    def punctuation_clear_list(text):\n",
    "        result = \"\"\n",
    "        for i in text:\n",
    "            for a in i:\n",
    "                if( a not in string.punctuation or a == \".\" or a == \" \" ):\n",
    "                    result+= a \n",
    "            \n",
    "        return result\n",
    "    content_clears = punctuation_clear(content_clear)\n",
    "    content_split_sentence = punctuation_clear_list(content_clear).split(\".\")\n",
    "    content_word_split= set(content_clears.split())\n",
    "    word_list= list()\n",
    "    say = 0\n",
    "    for i in content_word_split:\n",
    "        if(len(i)>=3):\n",
    "            word_list.append(i)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fa4385b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423\n"
     ]
    }
   ],
   "source": [
    "sentence_list_last = list()\n",
    "for a in word_list:\n",
    "    x=0\n",
    "    for i in content_split_sentence:\n",
    "        sentence = i.split()\n",
    "        for j in sentence:\n",
    "            if a==j:\n",
    "                sentence_list_last.append(i)\n",
    "                x+=1\n",
    "            if x==1:\n",
    "                break\n",
    "        if x==1:\n",
    "            break\n",
    "            \n",
    "content_clear_split_last = list()\n",
    "\n",
    "    \n",
    "say = 0\n",
    "for i in sentence_list_last:\n",
    "    say+=1\n",
    "print(say)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5888add4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stem_list=[]\n",
    "\n",
    "for i in word_list:\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    stem_list.append(stemmer.stem(i))\n",
    "#stem_set = set(stem_list)\n",
    "#stem_list = list(stem_set)\n",
    "a=  0\n",
    "for i in stem_list:\n",
    "    a+=1\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b875de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "ceviri_list= list()\n",
    "for i in word_list:\n",
    "    translation = translator.translate(i,dest = 'tr')\n",
    "    ceviri_list.append(translation.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cacdcf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import state_union\n",
    "import nltk\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "code_list = list()\n",
    "for i in word_list:\n",
    "        words = nltk.word_tokenize(i)\n",
    "        tagged = nltk.pos_tag(words)\n",
    "        code_list.append(tagged[0][1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55c930d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dict = {\"Code:\":code_list,\"Raw\":word_list,\"Root\":stem_list,\"Translation\":ceviri_list,\"Sentence\":sentence_list_last}\n",
    "df= pd.DataFrame(dict)\n",
    "df.to_csv(\"Computer Reading Translate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d171f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Code:</th>\n",
       "      <th>Raw</th>\n",
       "      <th>Root</th>\n",
       "      <th>Translation</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RBR</td>\n",
       "      <td>more</td>\n",
       "      <td>more</td>\n",
       "      <td>daha fazla</td>\n",
       "      <td>As computer systems are developed they are be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NN</td>\n",
       "      <td>video</td>\n",
       "      <td>video</td>\n",
       "      <td>video</td>\n",
       "      <td>A multimedia computer can process different f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>VBN</td>\n",
       "      <td>called</td>\n",
       "      <td>call</td>\n",
       "      <td>aranan</td>\n",
       "      <td>A special set of programs called an operating...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NN</td>\n",
       "      <td>computer</td>\n",
       "      <td>comput</td>\n",
       "      <td>bilgisayar</td>\n",
       "      <td>A computer is a device that processes dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NN</td>\n",
       "      <td>multipurpose</td>\n",
       "      <td>multipurpos</td>\n",
       "      <td>çok amaçlı</td>\n",
       "      <td>They are multipurpose tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>418</td>\n",
       "      <td>NN</td>\n",
       "      <td>built</td>\n",
       "      <td>built</td>\n",
       "      <td>inşa edilmiş</td>\n",
       "      <td>This enables computers to be built into other...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>419</td>\n",
       "      <td>VBG</td>\n",
       "      <td>clicking</td>\n",
       "      <td>click</td>\n",
       "      <td>tıklama</td>\n",
       "      <td>clicking the mouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>420</td>\n",
       "      <td>NN</td>\n",
       "      <td>example</td>\n",
       "      <td>exampl</td>\n",
       "      <td>örnek</td>\n",
       "      <td>Medical expert systems for example can help d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>421</td>\n",
       "      <td>NNS</td>\n",
       "      <td>documents</td>\n",
       "      <td>document</td>\n",
       "      <td>belgeler</td>\n",
       "      <td>The Web contains interlinked documents called...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>422</td>\n",
       "      <td>NN</td>\n",
       "      <td>name</td>\n",
       "      <td>name</td>\n",
       "      <td>isim</td>\n",
       "      <td>It is also possible to build all the m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>423 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0 Code:           Raw         Root   Translation  \\\n",
       "0             0   RBR          more         more    daha fazla   \n",
       "1             1    NN         video        video         video   \n",
       "2             2   VBN        called         call        aranan   \n",
       "3             3    NN      computer       comput    bilgisayar   \n",
       "4             4    NN  multipurpose  multipurpos    çok amaçlı   \n",
       "..          ...   ...           ...          ...           ...   \n",
       "418         418    NN         built        built  inşa edilmiş   \n",
       "419         419   VBG      clicking        click       tıklama   \n",
       "420         420    NN       example       exampl         örnek   \n",
       "421         421   NNS     documents     document      belgeler   \n",
       "422         422    NN          name         name          isim   \n",
       "\n",
       "                                              Sentence  \n",
       "0     As computer systems are developed they are be...  \n",
       "1     A multimedia computer can process different f...  \n",
       "2     A special set of programs called an operating...  \n",
       "3         A computer is a device that processes dat...  \n",
       "4                          They are multipurpose tools  \n",
       "..                                                 ...  \n",
       "418   This enables computers to be built into other...  \n",
       "419                                 clicking the mouse  \n",
       "420   Medical expert systems for example can help d...  \n",
       "421   The Web contains interlinked documents called...  \n",
       "422          It is also possible to build all the m...  \n",
       "\n",
       "[423 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv(\"Computer Reading Translate.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f5ed4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "config = {\"textlanguage\":\"en\",\n",
    "    \"translanguage\": \"en\",\n",
    "    \"saveloc\": 'Semih\\Documents\\VocabCam\\WordList'}\n",
    "with open('config.json', 'w') as file:\n",
    "    json.dump(config, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55c395ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json','r') as file:\n",
    "    config = json.load(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5f16f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Semih\\\\Documents\\\\VocabCam\\\\WordList'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60622d86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8dac34539f472889cfe55f2ed6694af900a23bf83e4a45908353ce84e7dbf49d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
