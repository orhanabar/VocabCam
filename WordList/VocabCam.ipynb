{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bea5276a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import string \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from googletrans import Translator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81af9510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def File_Content(file_name):\n",
    "    file_str = ''\n",
    "\n",
    "    if file_name.endswith('.pdf'):\n",
    "        pdf_file = convert_from_path(file_name)\n",
    "\n",
    "        for i in range(len(pdf_file)):\n",
    "            pdf_file[i].save(f'page{str(i + 1)}.jpg', 'JPEG')   # Saves pages as images in the pdf\n",
    "            file = f'page{str(i + 1)}.jpg'\n",
    "            file_str += pytesseract.image_to_string(file)\n",
    "            # os.remove(file)   # Deletes saved image files\n",
    "    elif file_name.endswith(('.jpg', '.png')):\n",
    "        file_str = pytesseract.image_to_string(file_name)\n",
    "        \n",
    "    return file_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b90ec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_cont= File_Content('Computer Reading.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a50414e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"Deneme.txt\",\"a\",encoding=\"utf-8\") as file:\n",
    "    file.write(file_cont)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa863202",
   "metadata": {},
   "outputs": [],
   "source": [
    "    with open(\"Deneme.txt\",\"r+\",encoding=\"utf-8\") as file:\n",
    "        content= file.readlines()\n",
    "        parag=  file.read()\n",
    "    \n",
    "\n",
    "        untitled=\"\"\n",
    "        for i in content:\n",
    "            if(i.isupper()==True or (i.istitle()==True)):\n",
    "                untitled += \" \"\n",
    "            else:\n",
    "                untitled += i + \" \"\n",
    "    with open(\"Computer Reading Son.txt\",\"a\",encoding=\"utf-8\") as file1:\n",
    "        for i in untitled:\n",
    "            file1.write(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7be3c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "from nltk.tokenize import sent_tokenize\n",
    "with open(\"Computer Reading Son.txt\",\"r\",encoding=\"utf-8\") as file: \n",
    "    contents=file.read()\n",
    "    content_clear =contents.replace(\"\\n\",\"\")\n",
    "    content_clear = content_clear.replace(\"/n\",\"\")\n",
    "    \n",
    "    def punctuation_clear(text):\n",
    "        result = \"\"\n",
    "        for i in text:\n",
    "            if( i not in string.punctuation or i == \" \" ):\n",
    "                result+= i \n",
    "            else:\n",
    "                result+= \"\"\n",
    "        return result\n",
    "    def punctuation_clear_list(text):\n",
    "        result = \"\"\n",
    "        for i in text:\n",
    "            for a in i:\n",
    "                if( a not in string.punctuation or a == \".\" or a == \" \" ):\n",
    "                    result+= a \n",
    "            \n",
    "        return result\n",
    "    content_clears = punctuation_clear(content_clear)\n",
    "    content_split_sentence = punctuation_clear_list(content_clear).split(\".\")\n",
    "    content_word_split= set(content_clears.split())\n",
    "    word_list= list()\n",
    "    say = 0\n",
    "    for i in content_word_split:\n",
    "        if(len(i)>=3):\n",
    "            word_list.append(i)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fa4385b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423\n"
     ]
    }
   ],
   "source": [
    "sentence_list_last = list()\n",
    "for a in word_list:\n",
    "    x=0\n",
    "    for i in content_split_sentence:\n",
    "        sentence = i.split()\n",
    "        for j in sentence:\n",
    "            if a==j:\n",
    "                sentence_list_last.append(i)\n",
    "                x+=1\n",
    "            if x==1:\n",
    "                break\n",
    "        if x==1:\n",
    "            break\n",
    "            \n",
    "content_clear_split_last = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5888add4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stem_list=[]\n",
    "\n",
    "for i in word_list:\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    stem_list.append(stemmer.stem(i))\n",
    "#stem_set = set(stem_list)\n",
    "#stem_list = list(stem_set)\n",
    "a=  0\n",
    "for i in stem_list:\n",
    "    a+=1\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b875de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "ceviri_list= list()\n",
    "for i in word_list:\n",
    "    translation = translator.translate(i,dest = 'tr')\n",
    "    ceviri_list.append(translation.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cacdcf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import state_union\n",
    "import nltk\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "code_list = list()\n",
    "for i in word_list:\n",
    "        words = nltk.word_tokenize(i)\n",
    "        tagged = nltk.pos_tag(words)\n",
    "        code_list.append(tagged[0][1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55c930d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dict = {\"Code:\":code_list,\"Raw\":word_list,\"Root\":stem_list,\"Translation\":ceviri_list,\"Sentence\":sentence_list_last}\n",
    "df= pd.DataFrame(dict)\n",
    "df.to_csv(\"Computer Reading Translate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d171f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import string \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from googletrans import Translator\n",
    "import pandas as pd\n",
    "import string \n",
    "from nltk.tokenize import sent_tokenize\n",
    "from PyDictionary import PyDictionary\n",
    "import json\n",
    "\n",
    "code_list1 = list()\n",
    "word_list1 = list()\n",
    "def vocab_cam(file_name1):\n",
    "    def File_Content(file_name):\n",
    "        file_str = ''\n",
    "\n",
    "        if file_name.endswith('.pdf'):\n",
    "            pdf_file = convert_from_path(file_name)\n",
    "\n",
    "            for i in range(len(pdf_file)):\n",
    "                pdf_file[i].save(f'page{str(i + 1)}.jpg', 'JPEG')   # Saves pages as images in the pdf\n",
    "                file = f'page{str(i + 1)}.jpg'\n",
    "                file_str += pytesseract.image_to_string(file)\n",
    "                # os.remove(file)   # Deletes saved image files\n",
    "        elif file_name.endswith(('.jpg', '.png')):\n",
    "            file_str = pytesseract.image_to_string(file_name)   \n",
    "        return file_str\n",
    "    file_cont= File_Content(file_name1)\n",
    "    \n",
    "    with open(\"Deneme.txt\",\"a\",encoding=\"utf-8\") as file:\n",
    "        file.write(file_cont)  \n",
    "    with open(\"Deneme.txt\",\"r+\",encoding=\"utf-8\") as file:\n",
    "        content= file.readlines()\n",
    "        parag=  file.read()\n",
    "        untitled=\"\"\n",
    "        for i in content:\n",
    "            if(i.isupper()==True or (i.istitle()==True)):\n",
    "                untitled += \" \"\n",
    "            else:\n",
    "                untitled += i + \" \"\n",
    "    with open(\"Computer Reading Son.txt\",\"a\",encoding=\"utf-8\") as file1:\n",
    "        for i in untitled:\n",
    "            file1.write(i)\n",
    "    with open(\"Computer Reading Son.txt\",\"r\",encoding=\"utf-8\") as file:\n",
    "        contents=file.read()\n",
    "        content_clear =contents.replace(\"\\n\",\"\")\n",
    "        content_clear = content_clear.replace(\"/n\",\"\")\n",
    "        def punctuation_clear(text):\n",
    "            result = \"\"\n",
    "            for i in text:\n",
    "                if( i not in string.punctuation or i == \" \" ):\n",
    "                    result+= i \n",
    "                else:\n",
    "                    result+= \"\"\n",
    "            return result                \n",
    "        \n",
    "        def punctuation_clear_list(text):\n",
    "            result = \"\"\n",
    "            for i in text:\n",
    "                for a in i:\n",
    "                    if( a not in string.punctuation or a == \".\" or a == \" \" ):\n",
    "                        result+= a \n",
    "            return result\n",
    "        content_clears = punctuation_clear(content_clear)\n",
    "        content_split_sentence = punctuation_clear_list(content_clear).split(\".\")\n",
    "        content_word_split= set(content_clears.split())\n",
    "        word_list= list()\n",
    "        \n",
    "        for i in content_word_split:\n",
    "            if(len(i)>=3):\n",
    "                word_list.append(i)\n",
    "        say1=0\n",
    "        for q in word_list:\n",
    "            say1+=1\n",
    "            word_list1.append(q)\n",
    "        print(\"Kelime Listesi : \",say1)\n",
    "    \n",
    "    p=0\n",
    "    sentence_list_last = list()\n",
    "    for w in word_list:\n",
    "        \n",
    "        num=0\n",
    "        for r in content_split_sentence:\n",
    "            sentence = r.split()\n",
    "            for e in sentence:\n",
    "                if w==e:\n",
    "                    sentence_list_last.append(r)\n",
    "                    num+=1\n",
    "                if num==1:\n",
    "                    break\n",
    "            if num==1:\n",
    "                break\n",
    "    say2=0\n",
    "    for q in sentence_list_last:\n",
    "        say2+=1\n",
    "    print(\"Cümle Listesi : \",say2)            \n",
    "    content_clear_split_last = list()\n",
    "    from nltk.stem.snowball import SnowballStemmer\n",
    "    stem_list=[]\n",
    "\n",
    "    for i in word_list:\n",
    "        stemmer = SnowballStemmer(\"english\")\n",
    "        stem_list.append(stemmer.stem(i))\n",
    "    #stem_set = set(stem_list)\n",
    "    #stem_list = list(stem_set)\n",
    "    say3=0\n",
    "    for q in stem_list:\n",
    "        say3+=1\n",
    "    print(\"kök Listesi : \",say3)\n",
    "    from googletrans import Translator\n",
    "    translator = Translator()\n",
    "    ceviri_list= list()\n",
    "    for i in word_list:\n",
    "        translation = translator.translate(i,dest = 'tr')\n",
    "        ceviri_list.append(translation.text)\n",
    "    say4=0\n",
    "    for q in ceviri_list:\n",
    "        say4+=1\n",
    "    print(\"çeviri Listesi : \",say4)\n",
    "    from nltk.corpus import state_union\n",
    "    import nltk\n",
    "    from nltk.tokenize import PunktSentenceTokenizer\n",
    "    code_list = list()\n",
    "    for i in word_list:\n",
    "        words = nltk.word_tokenize(i)\n",
    "        tagged = nltk.pos_tag(words)\n",
    "        code_list.append(tagged[0][1])\n",
    "    say5=0\n",
    "    for q in code_list:\n",
    "        say5+=1\n",
    "        code_list1.append(q)\n",
    "    print(\"kod Listesi : \",say5)\n",
    "    dictionary = PyDictionary()\n",
    "    pydictlist = list()\n",
    "    counter = 0\n",
    "    for i in code_list:\n",
    "        try:\n",
    "            if(i==\"NN\" or i==\"NNS\" or i==\"NNP\" or i == \"NNPS\"):\n",
    "                definition=dictionary.meaning(word_list[counter],disable_errors=True)[\"Noun\"][0]\n",
    "                pydictlist.append(definition)\n",
    "            elif(i == \"VB\" or i == \"VBD\" or i == \"VBG\" or i == \"VBN\" or i == \"VBP\" or i  == \"VBZ\" ):\n",
    "                definition=dictionary.meaning(word_list[counter],disable_errors=True)[\"Verb\"][0]\n",
    "                pydictlist.append(definition)\n",
    "            else:\n",
    "                pydictlist.append(\"None\")\n",
    "        except TypeError:\n",
    "            pydictlist.append(\"None\")\n",
    "        except KeyError:\n",
    "            pydictlist.append(\"None\")\n",
    "        except ValueError:\n",
    "            pydictlist.append(\"None\")\n",
    "        except IndexError:\n",
    "            pydictlist.append(\"None\")\n",
    "        counter +=1\n",
    "    \n",
    "    dict = {\"Code:\":code_list,\"Raw\":word_list,\"Root\":stem_list,\"Translation\":ceviri_list,\"Eng Translation\":pydictlist,\"Sentence\":sentence_list_last,}\n",
    "    df= pd.DataFrame(dict)\n",
    "    df.to_json(\"Computer Reading Translate.json\")\n",
    "    return df\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f5ed4dc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kelime Listesi :  423\n",
      "Cümle Listesi :  423\n",
      "kök Listesi :  423\n",
      "çeviri Listesi :  423\n",
      "kod Listesi :  423\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code:</th>\n",
       "      <th>Raw</th>\n",
       "      <th>Root</th>\n",
       "      <th>Translation</th>\n",
       "      <th>Eng Translation</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NN</td>\n",
       "      <td>account</td>\n",
       "      <td>account</td>\n",
       "      <td>hesap</td>\n",
       "      <td>a record or narrative description of past events</td>\n",
       "      <td>without any delay while the users are logged ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IN</td>\n",
       "      <td>Wide</td>\n",
       "      <td>wide</td>\n",
       "      <td>Geniş</td>\n",
       "      <td>None</td>\n",
       "      <td>One of the newest and most popular services ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VBG</td>\n",
       "      <td>clicking</td>\n",
       "      <td>click</td>\n",
       "      <td>tıklama</td>\n",
       "      <td>move or strike with a noise</td>\n",
       "      <td>clicking the mouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VBG</td>\n",
       "      <td>producing</td>\n",
       "      <td>produc</td>\n",
       "      <td>üreten</td>\n",
       "      <td>bring forth or yield</td>\n",
       "      <td>Computer uses mentioned in this unit include ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NN</td>\n",
       "      <td>‘computer</td>\n",
       "      <td>comput</td>\n",
       "      <td>'bilgisayar</td>\n",
       "      <td>None</td>\n",
       "      <td>the ‘computer on a chip’</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>NN</td>\n",
       "      <td>displayed</td>\n",
       "      <td>display</td>\n",
       "      <td>görüntülenen</td>\n",
       "      <td>None</td>\n",
       "      <td>The main device for inputting the data is a t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>VBN</td>\n",
       "      <td>referred</td>\n",
       "      <td>refer</td>\n",
       "      <td>sevk</td>\n",
       "      <td>make reference to</td>\n",
       "      <td>Devices that include a computer circuit are c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>NN</td>\n",
       "      <td>smart</td>\n",
       "      <td>smart</td>\n",
       "      <td>akıllı</td>\n",
       "      <td>a kind of pain such as that caused by a wound ...</td>\n",
       "      <td>smart cards which are able to store informati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>NN</td>\n",
       "      <td>health</td>\n",
       "      <td>health</td>\n",
       "      <td>sağlık</td>\n",
       "      <td>a healthy state of wellbeing free from disease</td>\n",
       "      <td>smart cards which are able to store informati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>JJ</td>\n",
       "      <td>main</td>\n",
       "      <td>main</td>\n",
       "      <td>ana</td>\n",
       "      <td>None</td>\n",
       "      <td>The main device for inputting the data is a t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>423 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Code:        Raw     Root   Translation  \\\n",
       "0      NN    account  account         hesap   \n",
       "1      IN       Wide     wide         Geniş   \n",
       "2     VBG   clicking    click       tıklama   \n",
       "3     VBG  producing   produc        üreten   \n",
       "4      NN  ‘computer   comput   'bilgisayar   \n",
       "..    ...        ...      ...           ...   \n",
       "418    NN  displayed  display  görüntülenen   \n",
       "419   VBN   referred    refer          sevk   \n",
       "420    NN      smart    smart        akıllı   \n",
       "421    NN     health   health        sağlık   \n",
       "422    JJ       main     main           ana   \n",
       "\n",
       "                                       Eng Translation  \\\n",
       "0     a record or narrative description of past events   \n",
       "1                                                 None   \n",
       "2                          move or strike with a noise   \n",
       "3                                 bring forth or yield   \n",
       "4                                                 None   \n",
       "..                                                 ...   \n",
       "418                                               None   \n",
       "419                                  make reference to   \n",
       "420  a kind of pain such as that caused by a wound ...   \n",
       "421     a healthy state of wellbeing free from disease   \n",
       "422                                               None   \n",
       "\n",
       "                                              Sentence  \n",
       "0     without any delay while the users are logged ...  \n",
       "1      One of the newest and most popular services ...  \n",
       "2                                   clicking the mouse  \n",
       "3     Computer uses mentioned in this unit include ...  \n",
       "4                             the ‘computer on a chip’  \n",
       "..                                                 ...  \n",
       "418   The main device for inputting the data is a t...  \n",
       "419   Devices that include a computer circuit are c...  \n",
       "420   smart cards which are able to store informati...  \n",
       "421   smart cards which are able to store informati...  \n",
       "422   The main device for inputting the data is a t...  \n",
       "\n",
       "[423 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_cam('Computer Reading.pdf')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24453fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyDictionary import PyDictionary\n",
    "dictionary=PyDictionary()\n",
    "pydictlist= list()\n",
    "counter = 0\n",
    "\n",
    "for i in code_list1:\n",
    "    try:\n",
    "        if(i==\"NN\" or i==\"NNS\" or i==\"NNP\" or i == \"NNPS\"):\n",
    "            definition=dictionary.meaning(word_list1[counter],disable_errors=True)[\"Noun\"][0]\n",
    "            pydictlist.append(definition)\n",
    "        elif(i == \"VB\" or i == \"VBD\" or i == \"VBG\" or i == \"VBN\" or i == \"VBP\" or i  == \"VBZ\" ):\n",
    "            definition=dictionary.meaning(word_list1[counter],disable_errors=True)[\"Verb\"][0]\n",
    "            pydictlist.append(definition)\n",
    "        else:\n",
    "            pydictlist.append(\"None\")\n",
    "    except TypeError:\n",
    "        pydictlist.append(\"None\")\n",
    "    except KeyError:\n",
    "        pydictlist.append(\"None\")\n",
    "    except ValueError:\n",
    "        pydictlist.append(\"None\")\n",
    "    except IndexError:\n",
    "        pydictlist.append(\"None\")\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "405ee9e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "423"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pydictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe020ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8dac34539f472889cfe55f2ed6694af900a23bf83e4a45908353ce84e7dbf49d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
