{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bea5276a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import string \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from googletrans import Translator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81af9510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def File_Content(file_name):\n",
    "    file_str = ''\n",
    "\n",
    "    if file_name.endswith('.pdf'):\n",
    "        pdf_file = convert_from_path(file_name)\n",
    "\n",
    "        for i in range(len(pdf_file)):\n",
    "            pdf_file[i].save(f'page{str(i + 1)}.jpg', 'JPEG')   # Saves pages as images in the pdf\n",
    "            file = f'page{str(i + 1)}.jpg'\n",
    "            file_str += pytesseract.image_to_string(file)\n",
    "            # os.remove(file)   # Deletes saved image files\n",
    "    elif file_name.endswith(('.jpg', '.png')):\n",
    "        file_str = pytesseract.image_to_string(file_name)\n",
    "        \n",
    "    return file_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b90ec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_cont= File_Content('Computer Reading.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a50414e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"Deneme.txt\",\"a\",encoding=\"utf-8\") as file:\n",
    "    file.write(file_cont)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa863202",
   "metadata": {},
   "outputs": [],
   "source": [
    "    with open(\"Deneme.txt\",\"r+\",encoding=\"utf-8\") as file:\n",
    "        content= file.readlines()\n",
    "        parag=  file.read()\n",
    "    \n",
    "\n",
    "        untitled=\"\"\n",
    "        for i in content:\n",
    "            if(i.isupper()==True or (i.istitle()==True)):\n",
    "                untitled += \" \"\n",
    "            else:\n",
    "                untitled += i + \" \"\n",
    "    with open(\"Computer Reading Son.txt\",\"a\",encoding=\"utf-8\") as file1:\n",
    "        for i in untitled:\n",
    "            file1.write(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7be3c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "from nltk.tokenize import sent_tokenize\n",
    "with open(\"Computer Reading Son.txt\",\"r\",encoding=\"utf-8\") as file: \n",
    "    contents=file.read()\n",
    "    content_clear =contents.replace(\"\\n\",\"\")\n",
    "    content_clear = content_clear.replace(\"/n\",\"\")\n",
    "    \n",
    "    def punctuation_clear(text):\n",
    "        result = \"\"\n",
    "        for i in text:\n",
    "            if( i not in string.punctuation or i == \" \" ):\n",
    "                result+= i \n",
    "            else:\n",
    "                result+= \"\"\n",
    "        return result\n",
    "    def punctuation_clear_list(text):\n",
    "        result = \"\"\n",
    "        for i in text:\n",
    "            for a in i:\n",
    "                if( a not in string.punctuation or a == \".\" or a == \" \" ):\n",
    "                    result+= a \n",
    "            \n",
    "        return result\n",
    "    content_clears = punctuation_clear(content_clear)\n",
    "    content_split_sentence = punctuation_clear_list(content_clear).split(\".\")\n",
    "    content_word_split= set(content_clears.split())\n",
    "    word_list= list()\n",
    "    say = 0\n",
    "    for i in content_word_split:\n",
    "        if(len(i)>=3):\n",
    "            word_list.append(i)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fa4385b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423\n"
     ]
    }
   ],
   "source": [
    "sentence_list_last = list()\n",
    "for a in word_list:\n",
    "    x=0\n",
    "    for i in content_split_sentence:\n",
    "        sentence = i.split()\n",
    "        for j in sentence:\n",
    "            if a==j:\n",
    "                sentence_list_last.append(i)\n",
    "                x+=1\n",
    "            if x==1:\n",
    "                break\n",
    "        if x==1:\n",
    "            break\n",
    "            \n",
    "content_clear_split_last = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5888add4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stem_list=[]\n",
    "\n",
    "for i in word_list:\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    stem_list.append(stemmer.stem(i))\n",
    "#stem_set = set(stem_list)\n",
    "#stem_list = list(stem_set)\n",
    "a=  0\n",
    "for i in stem_list:\n",
    "    a+=1\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b875de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "ceviri_list= list()\n",
    "for i in word_list:\n",
    "    translation = translator.translate(i,dest = 'tr')\n",
    "    ceviri_list.append(translation.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cacdcf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import state_union\n",
    "import nltk\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "code_list = list()\n",
    "for i in word_list:\n",
    "        words = nltk.word_tokenize(i)\n",
    "        tagged = nltk.pos_tag(words)\n",
    "        code_list.append(tagged[0][1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55c930d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dict = {\"Code:\":code_list,\"Raw\":word_list,\"Root\":stem_list,\"Translation\":ceviri_list,\"Sentence\":sentence_list_last}\n",
    "df= pd.DataFrame(dict)\n",
    "df.to_csv(\"Computer Reading Translate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d171f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import string \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from googletrans import Translator\n",
    "import pandas as pd\n",
    "import string \n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def vocab_cam(file_name1):\n",
    "    def File_Content(file_name):\n",
    "        file_str = ''\n",
    "\n",
    "        if file_name.endswith('.pdf'):\n",
    "            pdf_file = convert_from_path(file_name)\n",
    "\n",
    "            for i in range(len(pdf_file)):\n",
    "                pdf_file[i].save(f'page{str(i + 1)}.jpg', 'JPEG')   # Saves pages as images in the pdf\n",
    "                file = f'page{str(i + 1)}.jpg'\n",
    "                file_str += pytesseract.image_to_string(file)\n",
    "                # os.remove(file)   # Deletes saved image files\n",
    "        elif file_name.endswith(('.jpg', '.png')):\n",
    "            file_str = pytesseract.image_to_string(file_name)   \n",
    "        return file_str\n",
    "    file_cont= File_Content(file_name1)\n",
    "    \n",
    "    with open(\"Deneme.txt\",\"a\",encoding=\"utf-8\") as file:\n",
    "        file.write(file_cont)  \n",
    "    with open(\"Deneme.txt\",\"r+\",encoding=\"utf-8\") as file:\n",
    "        content= file.readlines()\n",
    "        parag=  file.read()\n",
    "        untitled=\"\"\n",
    "        for i in content:\n",
    "            if(i.isupper()==True or (i.istitle()==True)):\n",
    "                untitled += \" \"\n",
    "            else:\n",
    "                untitled += i + \" \"\n",
    "    with open(\"Computer Reading Son.txt\",\"a\",encoding=\"utf-8\") as file1:\n",
    "        for i in untitled:\n",
    "            file1.write(i)\n",
    "    with open(\"Computer Reading Son.txt\",\"r\",encoding=\"utf-8\") as file:\n",
    "        contents=file.read()\n",
    "        content_clear =contents.replace(\"\\n\",\"\")\n",
    "        content_clear = content_clear.replace(\"/n\",\"\")\n",
    "        def punctuation_clear(text):\n",
    "            result = \"\"\n",
    "            for i in text:\n",
    "                if( i not in string.punctuation or i == \" \" ):\n",
    "                    result+= i \n",
    "                else:\n",
    "                    result+= \"\"\n",
    "            return result                \n",
    "        \n",
    "        def punctuation_clear_list(text):\n",
    "            result = \"\"\n",
    "            for i in text:\n",
    "                for a in i:\n",
    "                    if( a not in string.punctuation or a == \".\" or a == \" \" ):\n",
    "                        result+= a \n",
    "            return result\n",
    "        content_clears = punctuation_clear(content_clear)\n",
    "        content_split_sentence = punctuation_clear_list(content_clear).split(\".\")\n",
    "        content_word_split= set(content_clears.split())\n",
    "        word_list= list()\n",
    "        \n",
    "        for i in content_word_split:\n",
    "            if(len(i)>=3):\n",
    "                word_list.append(i)\n",
    "        say1=0\n",
    "        for q in word_list:\n",
    "            say1+=1\n",
    "        print(\"Kelime Listesi : \",say1)\n",
    "    \n",
    "    p=0\n",
    "    sentence_list_last = list()\n",
    "    for w in word_list:\n",
    "        \n",
    "        num=0\n",
    "        for r in content_split_sentence:\n",
    "            sentence = r.split()\n",
    "            for e in sentence:\n",
    "                if w==e:\n",
    "                    sentence_list_last.append(r)\n",
    "                    num+=1\n",
    "                if num==1:\n",
    "                    break\n",
    "            if num==1:\n",
    "                break\n",
    "    say2=0\n",
    "    for q in sentence_list_last:\n",
    "        say2+=1\n",
    "    print(\"Cümle Listesi : \",say2)            \n",
    "    content_clear_split_last = list()\n",
    "    from nltk.stem.snowball import SnowballStemmer\n",
    "    stem_list=[]\n",
    "\n",
    "    for i in word_list:\n",
    "        stemmer = SnowballStemmer(\"english\")\n",
    "        stem_list.append(stemmer.stem(i))\n",
    "    #stem_set = set(stem_list)\n",
    "    #stem_list = list(stem_set)\n",
    "    say3=0\n",
    "    for q in stem_list:\n",
    "        say3+=1\n",
    "    print(\"kök Listesi : \",say3)\n",
    "    from googletrans import Translator\n",
    "    translator = Translator()\n",
    "    ceviri_list= list()\n",
    "    for i in word_list:\n",
    "        translation = translator.translate(i,dest = 'tr')\n",
    "        ceviri_list.append(translation.text)\n",
    "    say4=0\n",
    "    for q in ceviri_list:\n",
    "        say4+=1\n",
    "    print(\"çeviri Listesi : \",say4)\n",
    "    from nltk.corpus import state_union\n",
    "    import nltk\n",
    "    from nltk.tokenize import PunktSentenceTokenizer\n",
    "    code_list = list()\n",
    "    for i in word_list:\n",
    "        words = nltk.word_tokenize(i)\n",
    "        tagged = nltk.pos_tag(words)\n",
    "        code_list.append(tagged[0][1])\n",
    "    say5=0\n",
    "    for q in code_list:\n",
    "        say5+=1\n",
    "    print(\"kod Listesi : \",say5)\n",
    "    import pandas as pd\n",
    "    dict = {\"Code:\":code_list,\"Raw\":word_list,\"Root\":stem_list,\"Translation\":ceviri_list,\"Sentence\":sentence_list_last}\n",
    "    df= pd.DataFrame(dict)\n",
    "    df.to_csv(\"Computer Reading Translate.csv\")\n",
    "    return df\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f5ed4dc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kelime Listesi :  423\n",
      "Cümle Listesi :  423\n",
      "kök Listesi :  423\n",
      "çeviri Listesi :  423\n",
      "kod Listesi :  423\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code:</th>\n",
       "      <th>Raw</th>\n",
       "      <th>Root</th>\n",
       "      <th>Translation</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VBG</td>\n",
       "      <td>calculating</td>\n",
       "      <td>calcul</td>\n",
       "      <td>Hesaplanıyor</td>\n",
       "      <td>Common applications programs include wordproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RBR</td>\n",
       "      <td>more</td>\n",
       "      <td>more</td>\n",
       "      <td>daha fazla</td>\n",
       "      <td>As computer systems are developed they are be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NN</td>\n",
       "      <td>copying</td>\n",
       "      <td>copi</td>\n",
       "      <td>kopyalama</td>\n",
       "      <td>Note that copying data from a larger server s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NNS</td>\n",
       "      <td>graphics</td>\n",
       "      <td>graphic</td>\n",
       "      <td>grafik</td>\n",
       "      <td>A multimedia computer can process different f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NN</td>\n",
       "      <td>keyboard</td>\n",
       "      <td>keyboard</td>\n",
       "      <td>tuş takımı</td>\n",
       "      <td>The main device for inputting the data is a t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>NN</td>\n",
       "      <td>chip’</td>\n",
       "      <td>chip</td>\n",
       "      <td>yonga'</td>\n",
       "      <td>the ‘computer on a chip’</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>NNS</td>\n",
       "      <td>records</td>\n",
       "      <td>record</td>\n",
       "      <td>kayıtlar</td>\n",
       "      <td>smart cards which are able to store informati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>NN</td>\n",
       "      <td>security</td>\n",
       "      <td>secur</td>\n",
       "      <td>güvenlik</td>\n",
       "      <td>They can be used in a very wide variety of si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>VBN</td>\n",
       "      <td>searched</td>\n",
       "      <td>search</td>\n",
       "      <td>arandı</td>\n",
       "      <td>Common applications programs include wordproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>JJ</td>\n",
       "      <td>interactive</td>\n",
       "      <td>interact</td>\n",
       "      <td>etkileşimli</td>\n",
       "      <td>An Internet system designed to provide free i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>423 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Code:          Raw      Root   Translation  \\\n",
       "0     VBG  calculating    calcul  Hesaplanıyor   \n",
       "1     RBR         more      more    daha fazla   \n",
       "2      NN      copying      copi     kopyalama   \n",
       "3     NNS     graphics   graphic        grafik   \n",
       "4      NN     keyboard  keyboard    tuş takımı   \n",
       "..    ...          ...       ...           ...   \n",
       "418    NN        chip’      chip        yonga'   \n",
       "419   NNS      records    record      kayıtlar   \n",
       "420    NN     security     secur      güvenlik   \n",
       "421   VBN     searched    search        arandı   \n",
       "422    JJ  interactive  interact   etkileşimli   \n",
       "\n",
       "                                              Sentence  \n",
       "0     Common applications programs include wordproc...  \n",
       "1     As computer systems are developed they are be...  \n",
       "2     Note that copying data from a larger server s...  \n",
       "3     A multimedia computer can process different f...  \n",
       "4     The main device for inputting the data is a t...  \n",
       "..                                                 ...  \n",
       "418                           the ‘computer on a chip’  \n",
       "419   smart cards which are able to store informati...  \n",
       "420   They can be used in a very wide variety of si...  \n",
       "421   Common applications programs include wordproc...  \n",
       "422   An Internet system designed to provide free i...  \n",
       "\n",
       "[423 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_cam('Computer Reading.pdf')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9473b4cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8dac34539f472889cfe55f2ed6694af900a23bf83e4a45908353ce84e7dbf49d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
