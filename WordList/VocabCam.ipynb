{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4ae783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import string \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from googletrans import Translator\n",
    "import pandas as pd\n",
    "import string \n",
    "from nltk.tokenize import sent_tokenize\n",
    "from PyDictionary import PyDictionary\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "code_list1 = list()\n",
    "word_list1 = list()\n",
    "def vocab_cam(file_name1,trans_lang,stem_check):\n",
    "    def File_Content(file_name):\n",
    "        file_str = ''\n",
    "\n",
    "        if file_name.endswith('.pdf'):\n",
    "            pdf_file = convert_from_path(file_name)\n",
    "\n",
    "            for i in range(len(pdf_file)):\n",
    "                pdf_file[i].save(f'page{str(i + 1)}.jpg', 'JPEG')   # Saves pages as images in the pdf\n",
    "                file = f'page{str(i + 1)}.jpg'\n",
    "                file_str += pytesseract.image_to_string(file)\n",
    "                # os.remove(file)   # Deletes saved image files\n",
    "        elif file_name.endswith(('.jpg', '.png')):\n",
    "            file_str = pytesseract.image_to_string(file_name)   \n",
    "        return file_str\n",
    "    file_cont= File_Content(file_name1)\n",
    "    \n",
    "    with open(\"Deneme.txt\",\"a\",encoding=\"utf-8\") as file:\n",
    "        file.write(file_cont)  \n",
    "    with open(\"Deneme.txt\",\"r+\",encoding=\"utf-8\") as file:\n",
    "        content= file.readlines()\n",
    "        parag=  file.read()\n",
    "        untitled=\"\"\n",
    "        for i in content:\n",
    "            if(i.isupper()==True or (i.istitle()==True)):\n",
    "                untitled += \" \"\n",
    "            else:\n",
    "                untitled += i + \" \"\n",
    "    with open(\"Computer Reading Son.txt\",\"a\",encoding=\"utf-8\") as file1:\n",
    "        for i in untitled:\n",
    "            file1.write(i)\n",
    "    with open(\"Computer Reading Son.txt\",\"r\",encoding=\"utf-8\") as file:\n",
    "        contents=file.read()\n",
    "        content_clear =contents.replace(\"\\n\",\"\")\n",
    "        content_clear = content_clear.replace(\"/n\",\"\")\n",
    "        def punctuation_clear(text):\n",
    "            result = \"\"\n",
    "            for i in text:\n",
    "                if( i not in string.punctuation and i.isalpha() != False or i == \" \"  ):\n",
    "                    result+= i \n",
    "                else:\n",
    "                    result+= \"\"\n",
    "            return result                \n",
    "        \n",
    "        def punctuation_clear_list(text):\n",
    "            result = \"\"\n",
    "            text=text.lower()\n",
    "            for i in text:\n",
    "                for a in i:\n",
    "                    if( a not in string.punctuation and a.isalpha() or a == \".\" or a == \" \" ):\n",
    "                        result+= a \n",
    "            return result\n",
    "        content_clears = punctuation_clear(content_clear)\n",
    "        content_split_sentence = punctuation_clear_list(content_clear).split(\".\")\n",
    "        content_word_split= set(content_clears.split())\n",
    "        word_list= list()\n",
    "        \n",
    "        for i in content_word_split:\n",
    "            if(len(i)>=3):\n",
    "                i = i.lower()\n",
    "                i=punctuation_clear(i)\n",
    "                word_list.append(i)\n",
    "        say1=0\n",
    "        for q in word_list:\n",
    "            say1+=1\n",
    "            word_list1.append(q)\n",
    "        print(\"Kelime Listesi : \",say1)\n",
    "    \n",
    "    ## CÜMLE AYIRMA KISMI\n",
    "    sentence_list_last = list()\n",
    "    for w in word_list:\n",
    "        \n",
    "        num=0\n",
    "        for r in content_split_sentence:\n",
    "            sentence = r.split()\n",
    "            for e in sentence:\n",
    "                if w==e:\n",
    "                    sentence_list_last.append(r)\n",
    "                    num+=1\n",
    "                if num==1:\n",
    "                    break\n",
    "            if num==1:\n",
    "                break\n",
    "    say2=0\n",
    "    for q in sentence_list_last:\n",
    "        say2+=1\n",
    "    print(\"Cümle Listesi : \",say2)            \n",
    "    content_clear_split_last = list()\n",
    "    \n",
    "    ##KÖK KISMI\n",
    "    from nltk.stem.snowball import SnowballStemmer\n",
    "    stem_list=[]\n",
    "    if(stem_check==True):\n",
    "        for i in word_list:\n",
    "            stemmer = SnowballStemmer(\"english\")\n",
    "            stem_list.append(stemmer.stem(i))\n",
    "        say3=0\n",
    "        for q in stem_list:\n",
    "            say3+=1\n",
    "        print(\"kök Listesi : \",say3)\n",
    "    \n",
    "   ##ÇEVİRİ KISMI  \n",
    "    from googletrans import Translator\n",
    "    translator = Translator()\n",
    "    ceviri_list= list()\n",
    "    empty_dict = {}\n",
    "    if(os.path.exists(\"TranslateList.pickle\")!=True):\n",
    "        pickling_on = open(\"TranslateList.pickle\",\"wb\")\n",
    "        pickle.dump(empty_dict,pickling_on)\n",
    "        pickling_on.close()\n",
    "    \n",
    "    pickle_off = open('TranslateList.pickle','rb')\n",
    "    data = pickle.load(pickle_off)\n",
    "    data_update= data \n",
    "    for i in word_list:\n",
    "        sayac = 0\n",
    "        for j in data:\n",
    "            if(i==j):\n",
    "                \n",
    "                ceviri_list.append(data[j])\n",
    "                \n",
    "                sayac=1\n",
    "                break\n",
    "        if sayac!=1:\n",
    "            translation = translator.translate(i,dest = trans_lang)\n",
    "            ceviri_list.append(translation.text)\n",
    "            data_update.update({i:translation.text}) \n",
    "    pickling_update = open('TranslateList.pickle','wb')\n",
    "    pickle.dump(data_update,pickling_update)\n",
    "    pickling_update.close()\n",
    "    say4=0\n",
    "    for q in ceviri_list:\n",
    "        say4+=1\n",
    "    print(\"çeviri Listesi : \",say4)\n",
    "    \n",
    "    \n",
    "    ## ETİKETLEME KISMI \n",
    "    from nltk.corpus import state_union\n",
    "    import nltk\n",
    "    from nltk.tokenize import PunktSentenceTokenizer\n",
    "    code_list = list()\n",
    "    for i in word_list:\n",
    "        words = nltk.word_tokenize(i)\n",
    "        tagged = nltk.pos_tag(words)\n",
    "        code_list.append(tagged[0][1])\n",
    "    say5=0\n",
    "    for q in code_list:\n",
    "        say5+=1\n",
    "        code_list1.append(q)\n",
    "    print(\"kod Listesi : \",say5)\n",
    "    dictionary = PyDictionary()\n",
    "    pydictlist = list()\n",
    "    counter = 0\n",
    "    for i in code_list:\n",
    "        try:\n",
    "            if(i==\"NN\" or i==\"NNS\" or i==\"NNP\" or i == \"NNPS\"):\n",
    "                definition=dictionary.meaning(word_list[counter],disable_errors=True)[\"Noun\"][0]\n",
    "                pydictlist.append(definition)\n",
    "            elif(i == \"VB\" or i == \"VBD\" or i == \"VBG\" or i == \"VBN\" or i == \"VBP\" or i  == \"VBZ\" ):\n",
    "                definition=dictionary.meaning(word_list[counter],disable_errors=True)[\"Verb\"][0]\n",
    "                pydictlist.append(definition)\n",
    "            else:\n",
    "                pydictlist.append(\"None\")\n",
    "        except TypeError:\n",
    "            pydictlist.append(\"None\")\n",
    "        except KeyError:\n",
    "            pydictlist.append(\"None\")\n",
    "        except ValueError:\n",
    "            pydictlist.append(\"None\")\n",
    "        except IndexError:\n",
    "            pydictlist.append(\"None\")\n",
    "        counter +=1\n",
    "    if(stem_check==True):\n",
    "        dict = {\"Code:\":code_list,\"Raw\":word_list,\"Root\":stem_list,\"Translation\":ceviri_list,\"Eng Translation\":pydictlist,\"Sentence\":sentence_list_last,}\n",
    "        df= pd.DataFrame(dict)\n",
    "        df.to_json(\"Computer Reading Translate.json\")\n",
    "    else:\n",
    "        dict = {\"Code:\":code_list,\"Raw\":word_list,\"Translation\":ceviri_list,\"Eng Translation\":pydictlist,\"Sentence\":sentence_list_last,}\n",
    "        df= pd.DataFrame(dict)\n",
    "        df.to_json(\"Computer Reading Translate.json\")\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f5ed4dc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kelime Listesi :  410\n",
      "Cümle Listesi :  410\n",
      "kök Listesi :  410\n",
      "çeviri Listesi :  410\n",
      "kod Listesi :  410\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code:</th>\n",
       "      <th>Raw</th>\n",
       "      <th>Root</th>\n",
       "      <th>Translation</th>\n",
       "      <th>Eng Translation</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JJ</td>\n",
       "      <td>common</td>\n",
       "      <td>common</td>\n",
       "      <td>yaygın</td>\n",
       "      <td>None</td>\n",
       "      <td>common applications programs include wordproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT</td>\n",
       "      <td>some</td>\n",
       "      <td>some</td>\n",
       "      <td>bazı</td>\n",
       "      <td>None</td>\n",
       "      <td>some operating systems have graphical user in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NNS</td>\n",
       "      <td>allows</td>\n",
       "      <td>allow</td>\n",
       "      <td>izin verir</td>\n",
       "      <td>None</td>\n",
       "      <td>a special set of programs called an operating...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NNS</td>\n",
       "      <td>experts</td>\n",
       "      <td>expert</td>\n",
       "      <td>uzmanlar</td>\n",
       "      <td>a person with special knowledge or ability who...</td>\n",
       "      <td>advanced systems known as expert systems enab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JJ</td>\n",
       "      <td>personal</td>\n",
       "      <td>person</td>\n",
       "      <td>kişiye özel</td>\n",
       "      <td>None</td>\n",
       "      <td>those designed for use by one person at a tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>NNS</td>\n",
       "      <td>ﬁles</td>\n",
       "      <td>ﬁles</td>\n",
       "      <td>dosyalar</td>\n",
       "      <td>None</td>\n",
       "      <td>an internet service called ftp file transfer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>RB</td>\n",
       "      <td>not</td>\n",
       "      <td>not</td>\n",
       "      <td>olumsuzluk</td>\n",
       "      <td>None</td>\n",
       "      <td>unlike most machines computers do not have a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>NN</td>\n",
       "      <td>capital</td>\n",
       "      <td>capit</td>\n",
       "      <td>Başkent</td>\n",
       "      <td>assets available for use in the production of ...</td>\n",
       "      <td>the connection of networks throughout the wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>NN</td>\n",
       "      <td>time</td>\n",
       "      <td>time</td>\n",
       "      <td>zaman</td>\n",
       "      <td>an instance or single occasion for some event</td>\n",
       "      <td>those designed for use by one person at a tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>NN</td>\n",
       "      <td>server</td>\n",
       "      <td>server</td>\n",
       "      <td>sunucu</td>\n",
       "      <td>a person whose occupation is to serve at table...</td>\n",
       "      <td>an internet service called ftp file transfer ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>410 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Code:       Raw    Root  Translation  \\\n",
       "0      JJ    common  common       yaygın   \n",
       "1      DT      some    some         bazı   \n",
       "2     NNS    allows   allow   izin verir   \n",
       "3     NNS   experts  expert     uzmanlar   \n",
       "4      JJ  personal  person  kişiye özel   \n",
       "..    ...       ...     ...          ...   \n",
       "405   NNS      ﬁles    ﬁles     dosyalar   \n",
       "406    RB       not     not   olumsuzluk   \n",
       "407    NN   capital   capit      Başkent   \n",
       "408    NN      time    time        zaman   \n",
       "409    NN    server  server       sunucu   \n",
       "\n",
       "                                       Eng Translation  \\\n",
       "0                                                 None   \n",
       "1                                                 None   \n",
       "2                                                 None   \n",
       "3    a person with special knowledge or ability who...   \n",
       "4                                                 None   \n",
       "..                                                 ...   \n",
       "405                                               None   \n",
       "406                                               None   \n",
       "407  assets available for use in the production of ...   \n",
       "408      an instance or single occasion for some event   \n",
       "409  a person whose occupation is to serve at table...   \n",
       "\n",
       "                                              Sentence  \n",
       "0     common applications programs include wordproc...  \n",
       "1     some operating systems have graphical user in...  \n",
       "2     a special set of programs called an operating...  \n",
       "3     advanced systems known as expert systems enab...  \n",
       "4     those designed for use by one person at a tim...  \n",
       "..                                                 ...  \n",
       "405   an internet service called ftp file transfer ...  \n",
       "406    unlike most machines computers do not have a...  \n",
       "407   the connection of networks throughout the wor...  \n",
       "408   those designed for use by one person at a tim...  \n",
       "409   an internet service called ftp file transfer ...  \n",
       "\n",
       "[410 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_cam('Computer Reading.pdf',\"tr\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c491a697",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8dac34539f472889cfe55f2ed6694af900a23bf83e4a45908353ce84e7dbf49d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
